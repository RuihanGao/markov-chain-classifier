{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the object\n",
    "object_names = ['bathTowel',\n",
    "                 'cardBoard',\n",
    "                 'carpetNet',\n",
    "                 'cork',\n",
    "                 'cotton',\n",
    "                 'cuisionFoam',\n",
    "                 'denim',\n",
    "                 'eva',\n",
    "                 'fakeLeather',\n",
    "                 'felt',\n",
    "                 'fiberBoard',\n",
    "                 'metal',\n",
    "                 'paper1',\n",
    "                 'paper2',\n",
    "                 'polypropileno',\n",
    "                 'polypropilenoSmooth',\n",
    "                 'softMaterial1',\n",
    "                 'softMaterial2',\n",
    "                 'spongeWhiteSmall',\n",
    "                 'styrofoam',\n",
    "                 'thinPolypropylene',\n",
    "                 'woodHard',\n",
    "                 'yogaMat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected window size\n",
    "DEPTH_SIZE = 75\n",
    "\n",
    "# acceleration and decelaration angle size (in degrees)\n",
    "epsilon_lim = 1\n",
    "\n",
    "lower_lim = 30+epsilon_lim\n",
    "upper_lim = 90-epsilon_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name conventions\n",
    "new_names = {}\n",
    "for i in range(1,386):\n",
    "    new_names[i] = i-1\n",
    "    \n",
    "# these taxels are meaningless: every 7 and 11 (out 12)\n",
    "meaningless_taxels = []\n",
    "for i in range(0,193, 12):\n",
    "    meaningless_taxels.append(i+7)\n",
    "    meaningless_taxels.append(i+11)\n",
    "    \n",
    "useful_triangle = [4, 5, 6, 7, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "drop_columns = range(193, 385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_folder = 'TactileLearning/tactile_dataset_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ TACTILE\n",
    "def read_tactile(obj_name):\n",
    "    \n",
    "    # read object data file\n",
    "    df = pd.read_csv(dir_folder + obj_name + '/slide_raw/right_forearm_comp/data.log', sep = ' ', header=None).drop([0, 1], axis=1)\n",
    "    df = df.rename(columns=new_names)\n",
    "    df = df.drop(drop_columns, axis=1)\n",
    "    #df = df.rename(columns={0:'t'})\n",
    "    \n",
    "    drop_taxels = []\n",
    "    for taxel in df.columns:\n",
    "        if (taxel in meaningless_taxels) or ( int(np.ceil(taxel/12)) not in useful_triangle ):\n",
    "            drop_taxels.append(taxel)\n",
    "    df = df.drop(drop_taxels, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_picks(ll):\n",
    "    # choose picks\n",
    "    picks = []\n",
    "    for i in ll.index:\n",
    "        add_it = True\n",
    "        for j in picks:\n",
    "            if i-j <= 40:\n",
    "                add_it = False\n",
    "                break\n",
    "        if(add_it):\n",
    "            picks.append(i)\n",
    "    return picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_encoder(_filename):\n",
    "    # read encoder data\n",
    "    _file_dir_encoder =dir_folder +  _filename + '/slide_raw/right_arm_encoders/data.log'\n",
    "    _df_encoder = pd.read_csv(_file_dir_encoder, sep = ' ', header=None).drop([0], axis=1)\n",
    "    _df_encoder = _df_encoder.rename(columns={1:'t', 5:'elbow'})\n",
    "    _df_encoder = _df_encoder.loc[:, ['t', 'elbow']]\n",
    "    _df_encoder.loc[ :, 'elbow'] = savgol_filter(_df_encoder.loc[:,'elbow'].values, 41, 3)\n",
    "\n",
    "    # select the region by index\n",
    "    _mask = (_df_encoder.elbow >= lower_lim) & (_df_encoder.elbow <= upper_lim)\n",
    "    pre_peaks = pd.Series(0,index=_df_encoder.index)\n",
    "    pre_peaks[_mask] = 1\n",
    "    pre_peaks = pre_peaks.diff()\n",
    "    pre_peaks = pre_peaks[pre_peaks != 0]\n",
    "    pre_peaks = pre_peaks.drop(0)\n",
    "    \n",
    "    # filter peaks\n",
    "    _peaks = filter_picks(pre_peaks)\n",
    "    return _df_encoder, _peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_slide_data(test_inds):\n",
    "    train_labels = {}\n",
    "    test_labels = {}\n",
    "\n",
    "    #test_inds = list(np.linspace(1,13, 13, dtype='int')*4)\n",
    "\n",
    "    train_count= 0\n",
    "    test_count = 0\n",
    "\n",
    "    data_dir = 'slide_6_10/'\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "\n",
    "    for obj_name in object_names:\n",
    "\n",
    "        # read data\n",
    "        df_tactile = read_tactile(obj_name)\n",
    "        df_encoder, peaks = read_encoder(obj_name)\n",
    "\n",
    "        # read each slide\n",
    "        for i in range(62):\n",
    "            for j in range(1):\n",
    "                #for k in range(DEPTH_SIZE):\n",
    "\n",
    "                df_chunk = df_tactile.loc[peaks[2*i] : peaks[2*i] + DEPTH_SIZE -1, :].values.reshape(6,DEPTH_SIZE,10)\n",
    "                df_chunk = np.swapaxes(df_chunk, 1,2).astype('float64')\n",
    "                #chunk_tensor = torch.from_numpy(df_chunk)\n",
    "\n",
    "                name_convention = obj_name + '_' + str(i)\n",
    "                torch.save(torch.from_numpy(df_chunk), data_dir + name_convention + '.pt')\n",
    "\n",
    "                if i in test_inds:\n",
    "                    test_ids.append(name_convention)\n",
    "                    test_labels[name_convention] = object_names.index(obj_name)\n",
    "                    test_count += 1\n",
    "                else:\n",
    "                    train_ids.append(name_convention)\n",
    "                    train_labels[name_convention] = object_names.index(obj_name)\n",
    "                    train_count += 1\n",
    "    pickle.dump([train_ids, train_labels, test_ids, test_labels], open('slide_6_10.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
